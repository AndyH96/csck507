{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f69ce32",
   "metadata": {},
   "source": [
    "# CSCK507 Mid Module - Toxic Comment Classification Challenge\n",
    "\n",
    "## Table of Contents\n",
    "[Section 1. Introduction](#introduction)\n",
    "- [Import Dependencies](#import-dependencies)\n",
    "- [Initialise SpaCy Model ](#import-dependencies)\n",
    "\n",
    "[Section 2. Data Exploration & Analysis](#data-exploration-&-analysis)\n",
    "  - [Dataset Alignment](#data-preprocessing)\n",
    "  - [Data Preprocessing](#data-preprocessing)\n",
    "  - [Tokenisation & Lemmatisation](#data-preprocessing)\n",
    "  - [Combining Tokenised Data and Labels for Training and Test Dataset](#data-preprocessing)\n",
    "  \n",
    "    [2.1 Requirements](#data-exploration-&-analysis)\n",
    "      - [Number of Sentences & Tokens Per Class](#data-preprocessing)\n",
    "      - [Understanding the Most Common Words](#data-preprocessing)\n",
    "      - [Data Imbalance](#data-imbalance)\n",
    "  \n",
    "[Section 3. Feature Extraction Methods](#data-exploration-&-analysis)\n",
    "\n",
    "[Section 4. Machine Learning Models](#data-exploration-&-analysis)\n",
    "\n",
    "[Section 5. Model Evaluation](#data-exploration-&-analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35d39a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction\n",
    "\n",
    "Originating in 2018, this challenge revolves around classifying different levels of toxicity in online comments. The dataset from the inaugural competition is utilized to analyze and evaluate the performance of various machine learning algorithms in categorizing six types of toxicity. The primary goal is not only to find an optimal solution but to understand the process of evaluating machine learning algorithms' performance in a classification task. This individual assessment involves data analysis, algorithm selection, and the exploration of feature extraction methods to uncover insights into the nuances of toxic comment classification.\n",
    "\n",
    "The Toxic Comment Classification Challenge and dataset can be obtained from Kaggle, here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040f411",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3aae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import spacy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# For Data Preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re  \n",
    "\n",
    "# For Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#For Feature Extraction  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string \n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bbe01",
   "metadata": {},
   "source": [
    "### Loading Kaggle dataset into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd219e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "df_test_labels = pd.read_csv('./test_labels.csv')\n",
    "df_test_comment = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364504dd",
   "metadata": {},
   "source": [
    "### Initialise SpaCy Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1202eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spacy.prefer_gpu()\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except (LookupError, OSError):\n",
    "    print('Run: python -m spacy download en_core_web_sm')\n",
    "\n",
    "try:\n",
    "    nltk_stop = stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    nltk_stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f382cb",
   "metadata": {},
   "source": [
    "This code initialises SpaCy with GPU preference and downloads the 'English' language model if necessary. It also sets up NLTK by downloading the English stopwords list if not already available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038ddd4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5448474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e85c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n",
      "The table dimensions are: (159571, 8)\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print(\"The table dimensions are:\",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072d162",
   "metadata": {},
   "source": [
    "### Aligning Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53bf8b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels extracted successfully.\n",
      "df_test before removing -1: (153164, 7)\n",
      "df_test after removing -1: (63978, 7)\n",
      "Dataframes merged successfully.\n",
      "New DataFrame 'df_test' created successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Obtain class labels of the dataset\n",
    "    class_labels = list(df.columns[2:])\n",
    "    print(\"Class labels extracted successfully.\")\n",
    "\n",
    "    # Remove rows with -1 from df_test as they are not used for scoring\n",
    "    print(f'df_test before removing -1: {df_test_labels.shape}')\n",
    "    for class_label in class_labels:\n",
    "        df_test_labels = df_test_labels[df_test_labels[class_label] != -1]\n",
    "\n",
    "    print(f'df_test after removing -1: {df_test_labels.shape}')\n",
    "\n",
    "    # Left join 'df_test' and 'df_test_comment' on the 'id' column\n",
    "    df_test = pd.merge(df_test_labels, df_test_comment, on='id', how='left')\n",
    "    print(f\"Dataframes merged successfully.\")\n",
    "\n",
    "    # Create a new DataFrame called df_test and match the column structure of 'df'\n",
    "    df_test = df_test[['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "    print(\"New DataFrame 'df_test' created successfully.\")\n",
    "\n",
    "except KeyError as ke:\n",
    "    print(f\"Error: {ke} not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2825a",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b50e5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, nltk_stop=None):\n",
    "    try:\n",
    "        if nltk_stop is None:\n",
    "            nltk_stop = set(stopwords.words('english'))\n",
    "    except LookupError:\n",
    "        print(\"NLTK stopwords not available. Consider downloading with nltk.download('stopwords').\")\n",
    "\n",
    "    try:\n",
    "        # Combine URL removal, extra space replacement, and Non-English characters removal\n",
    "        text = re.sub(r\"(http\\S+|www\\S+|https\\S+)|[^\\x00-\\x7F]+\", \" \", text)\n",
    "        # Remove start and end white spaces\n",
    "        text = text.strip()\n",
    "        # Remove single characters\n",
    "        text = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", text)\n",
    "        # Remove punctuations and convert to lowercase\n",
    "        text = re.sub(r\"[^a-zA-Z0-9]+\", \" \", text).lower()\n",
    "        # Stopword Removal using set operations\n",
    "        text = ' '.join(set(text.split()) - nltk_stop)\n",
    "\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8512f77",
   "metadata": {},
   "source": [
    "The 'preprocess_text' function efficiently cleanses and standardises textual data for enhanced manageability. It removes distracting elements like URLs, special characters, and numbers, ensuring a focused text corpus. Handling issues such as extra spaces, newline characters, and non-English characters guarantees consistent text structure. The function simplifies vocabulary by removing single characters and punctuation, while converting text to lowercase aids in case-insensitive consistency. The final step involves removing common stopwords, refining the text for meaningful content. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0c244",
   "metadata": {},
   "source": [
    "### Tokenisation and Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9bb6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemma_text(documents):\n",
    "    \"\"\"\n",
    "    Tokenize a list of documents and perform the following:\n",
    "    1. Break text into individual words or subword tokens.\n",
    "    2. Reduce words to their base or root form using lemmatization.\n",
    "    3. Remove stop words and non-alphabetic characters.\n",
    "\n",
    "    Utilises spaCy's nlp.pipe for efficient batch processing.\n",
    "\n",
    "    :param documents: List of strings representing documents.\n",
    "    :return: List of lists of strings, where each list corresponds to the lemmatized tokens of a document.\n",
    "    \"\"\"\n",
    "    lemmatized_tokens_list = []\n",
    "    \n",
    "    # Process documents using spaCy's nlp.pipe with \"ner\" and \"parser\" components disabled utilising 4 core parallel processing:\n",
    "    for doc in nlp.pipe(documents, disable=[\"ner\", \"parser\"], batch_size=5000, n_process=4):\n",
    "        # Generate lemmatised tokens, remove stop words, and non-alphabetic characters\n",
    "        lemmatized_tokens = [token.lemma_ for token in doc if token.is_alpha and token.lemma_ not in nlp.Defaults.stop_words]\n",
    "        lemmatized_tokens_list.append(lemmatized_tokens)\n",
    "\n",
    "    return lemmatized_tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c76cc",
   "metadata": {},
   "source": [
    "In many tokenization tasks, especially when you're primarily interested in lemmatization and removing stop words, you may not need the additional information provided by the \"ner\" and \"parser\" components.\n",
    "\n",
    "Disabling the \"ner\" and \"parser\" components during the processing of documents with nlp.pipe will reduce computational laod and can significantly improve efficiency and speed, especially when dealing with a large amount of text data.\n",
    "\n",
    "It's a trade-off between computational resources and the specific linguistic information your task requires. If named entities and syntactic parsing are not critical for your task, disabling these components is a pragmatic approach to enhance processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e1c7971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed train dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation edits made username hardcore metal...      0   \n",
       "1  000103f0d9cfb60f  aww matches background colour seemingly stuck ...      0   \n",
       "2  000113f07ec002fd  hey man really trying edit war guy constantly ...      0   \n",
       "3  0001b41b1c6bb37e  make real suggestions improvement wondered sec...      0   \n",
       "4  0001d958c54c6e35                      sir hero chance remember page      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the train dataset\n",
    "df['comment_text'] = df['comment_text'].apply(preprocess_text)\n",
    "print(\"Preprocessed train dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78644ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed test dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>thank understanding think highly would revert ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>dear god site horrible</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>somebody invariably try add religion really me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>says right type type institution needed case t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>adding new product list make sure relevant add...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0001ea8717f6de06  thank understanding think highly would revert ...      0   \n",
       "1  000247e83dcc1211                             dear god site horrible      0   \n",
       "2  0002f87b16116a7f  somebody invariably try add religion really me...      0   \n",
       "3  0003e1cccfd5a40a  says right type type institution needed case t...      0   \n",
       "4  00059ace3e3e9a53  adding new product list make sure relevant add...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the test dataset\n",
    "df_test['comment_text'] = df_test['comment_text'].apply(preprocess_text)\n",
    "print(\"\\nPreprocessed test dataset:\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9301c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the train and test datasets\n",
    "tokenized_comment_train = tokenize_lemma_text(df['comment_text'].tolist())\n",
    "tokenized_comment_test = tokenize_lemma_text(df_test['comment_text'].tolist())\n",
    "\n",
    "# Get labels for train and test data\n",
    "y = df[class_labels]\n",
    "y_test = df_test[class_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10500f4a",
   "metadata": {},
   "source": [
    "### Combining Tokenised Text and Labels for Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ef579a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of df_train (Training Data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[explanation, edit, username, hardcore, metall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hey, man, try, edit, war, guy, constantly, re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[real, suggestion, improvement, wonder, sectio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic  severe_toxic  \\\n",
       "0  [explanation, edit, username, hardcore, metall...      0             0   \n",
       "1  [aww, match, background, colour, seemingly, st...      0             0   \n",
       "2  [hey, man, try, edit, war, guy, constantly, re...      0             0   \n",
       "3  [real, suggestion, improvement, wonder, sectio...      0             0   \n",
       "4                [sir, hero, chance, remember, page]      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of df_test (Test Data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[thank, understanding, think, highly, revert, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[dear, god, site, horrible]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[somebody, invariably, try, add, religion, mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[right, type, type, institution, need, case, l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[add, new, product, list, sure, relevant, add,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic  severe_toxic  \\\n",
       "0  [thank, understanding, think, highly, revert, ...      0             0   \n",
       "1                        [dear, god, site, horrible]      0             0   \n",
       "2  [somebody, invariably, try, add, religion, mea...      0             0   \n",
       "3  [right, type, type, institution, need, case, l...      0             0   \n",
       "4  [add, new, product, list, sure, relevant, add,...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For training data\n",
    "df_train = pd.DataFrame({\n",
    "    'comment': tokenized_comment_train,         # Tokenized comment text\n",
    "    'toxic': y['toxic'],                        # Toxicity label\n",
    "    'severe_toxic': y['severe_toxic'],          # Severe toxicity label\n",
    "    'obscene': y['obscene'],                    # Obscenity label\n",
    "    'threat': y['threat'],                      # Threatening language label\n",
    "    'insult': y['insult'],                      # Insult label\n",
    "    'identity_hate': y['identity_hate']         # Identity hate label\n",
    "})\n",
    "\n",
    "print(\"Head of df_train (Training Data):\")\n",
    "display(df_train.head())\n",
    "\n",
    "# For test data\n",
    "df_test = pd.DataFrame({\n",
    "    'comment': tokenized_comment_test,          # Tokenized comment text for testing\n",
    "    'toxic': y_test['toxic'],                   # Toxicity label for testing\n",
    "    'severe_toxic': y_test['severe_toxic'],     # Severe toxicity label for testing\n",
    "    'obscene': y_test['obscene'],               # Obscenity label for testing\n",
    "    'threat': y_test['threat'],                 # Threatening language label for testing\n",
    "    'insult': y_test['insult'],                 # Insult label for testing\n",
    "    'identity_hate': y_test['identity_hate']    # Identity hate label for testing\n",
    "})\n",
    "\n",
    "print(\"\\nHead of df_test (Test Data):\")\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2a784",
   "metadata": {},
   "source": [
    "### 2.2 Requirements\n",
    "\n",
    "We're going to review the data and it's Perform detailed data analysis of the dataset provided by the competition, observing:\n",
    "\n",
    "Number of sentences and tokens per class (and check if the dataset is unbalanced or not).\n",
    "\n",
    "Analyse the most common words for each class and, therefore, understand the most used terms for each level of toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5179685",
   "metadata": {},
   "source": [
    "### Counting Number of Sentences & Tokens Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a87d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store counts\n",
    "class_counts = {'class_label': [], 'num_sentences': [], 'num_tokens': []}\n",
    "\n",
    "# Iterate through each class\n",
    "for class_label in class_labels:\n",
    "    # Select comments for the current class\n",
    "    class_comments = df[df[class_label] != -1]['comment_text'].tolist()\n",
    "\n",
    "    # Initialize counters\n",
    "    total_sentences = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    # Iterate through comments in the current class\n",
    "    for comment in class_comments:\n",
    "        # Process the comment with spaCy\n",
    "        doc = nlp(comment)\n",
    "\n",
    "        # Count sentences and tokens\n",
    "        total_sentences += len(list(doc.sents))\n",
    "        total_tokens += len(doc)\n",
    "\n",
    "    # Update the counts in the dictionary\n",
    "    class_counts['class_label'].append(class_label)\n",
    "    class_counts['num_sentences'].append(total_sentences)\n",
    "    class_counts['num_tokens'].append(total_tokens)\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "class_counts_df = pd.DataFrame(class_counts)\n",
    "\n",
    "# Display the result\n",
    "print(class_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeaa30d",
   "metadata": {},
   "source": [
    "### Understanding the Most Common Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab4dae",
   "metadata": {},
   "source": [
    "### Exploring Class Distribution and Imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1957dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Loop through class columns and print class counts\n",
    "for column in class_columns:\n",
    "    class_counts = df[column].value_counts()\n",
    "    \n",
    "    print(f\"{column.capitalize()} Counts:\")\n",
    "    for index, count in class_counts.items():\n",
    "        class_label = \"Non-\" + column if index == 0 else column\n",
    "        print(f\"{class_label}: {count}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a stylish seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# Visualize the results with a dark palette\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x='class_label', y='num_sentences', data=class_counts_df, palette='dark')\n",
    "plt.title('Number of Sentences per Class')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='class_label', y='num_tokens', data=class_counts_df, palette='dark')\n",
    "plt.title('Number of Tokens per Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6d799",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature Extraction\n",
    "    \n",
    "### Create a TF-IDF \n",
    "vectoriser = TfTfidfVectorizer()\n",
    "transformed_output = v.fit_transform(\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b84d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181e8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ff6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff5f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
