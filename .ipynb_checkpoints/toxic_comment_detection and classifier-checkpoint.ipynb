{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f69ce32",
   "metadata": {},
   "source": [
    "# CSCK507 Mid-Module Assignment\n",
    "### Toxic comment classification challenge\n",
    "\n",
    "## Table of Contents\n",
    "[Section 1. Introduction](#introduction)\n",
    "- [Import Dependencies](#import-dependencies)\n",
    "\n",
    "[Section 2. Data Exploration & Analysis](#data-exploration-&-analysis)\n",
    "  - [2.1 Data Preprocessing](#data-preprocessing)\n",
    "  - [2.2 Data Imbalance](#data-imbalance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc4f3d2b",
   "metadata": {},
   "source": [
    "## 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6600910",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d3aae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import spacy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# For Data Preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re  \n",
    "\n",
    "# For Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "#For Feature Extraction  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string \n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdd219e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into pandas DataFrame with relative path\n",
    "\n",
    "df = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test_labels.csv')\n",
    "df_testcomments = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5510ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spacy.prefer_gpu()\n",
    "    spacy.load('en_core_web_sm')\n",
    "except LookupError:\n",
    "    print('Run: python -m spacy download en_core_web_sm')\n",
    "\n",
    "try:\n",
    "    nltk_stop = stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "502210cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise SpaCy Model \n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5053835a",
   "metadata": {},
   "source": [
    "## 2. Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bada3",
   "metadata": {},
   "source": [
    "Some chapter notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1957dae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0    144277\n",
      "1     15294\n",
      "Name: count, dtype: int64\n",
      "\n",
      "severe_toxic\n",
      "0    157976\n",
      "1      1595\n",
      "Name: count, dtype: int64\n",
      "\n",
      "obscene\n",
      "0    151122\n",
      "1      8449\n",
      "Name: count, dtype: int64\n",
      "\n",
      "threat\n",
      "0    159093\n",
      "1       478\n",
      "Name: count, dtype: int64\n",
      "\n",
      "insult\n",
      "0    151694\n",
      "1      7877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "identity_hate\n",
      "0    158166\n",
      "1      1405\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for column in class_columns:\n",
    "    class_counts = df[column].value_counts()\n",
    "    print(class_counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3e85c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53bf8b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test before removing -1: (63978, 9)\n",
      "df_test after removing -1: (63978, 9)\n"
     ]
    }
   ],
   "source": [
    "# Obtain class labels of the dataset\n",
    "class_labels = list(df.columns[2:])\n",
    "class_labels\n",
    "\n",
    "# Remove rows with -1 from df_test as they are not used for scoring\n",
    "print(f'df_test before removing -1: {df_test.shape}')\n",
    "for class_label in class_labels:\n",
    "    df_test = df_test[df_test[class_label] != -1]\n",
    "print(f'df_test after removing -1: {df_test.shape}')\n",
    "\n",
    "# Left join 'df_test' and 'df_testcomments' on the 'id' column\n",
    "df_test = pd.merge(df_test, df_testcomments, on='id', how='left')\n",
    "\n",
    "# Rearrange columns to match the structure of df\n",
    "df_test = df_test[['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7feae058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7478b",
   "metadata": {},
   "source": [
    "### 2.1 Data Preprocessing\n",
    "\n",
    "This part consists of... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b50e5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess a text string.\n",
    "\n",
    "    Operations performed:\n",
    "    - Replace special characters, URLs, and numbers with spaces.\n",
    "    - Remove extra spaces and replace \"\\n\" with a space.\n",
    "    - Remove Non-English characters.\n",
    "    - Remove start and end white spaces.\n",
    "    - Remove single characters.\n",
    "    - Remove punctuations.\n",
    "    - Convert the text to lowercase.\n",
    "    - Remove common stopwords.\n",
    "\n",
    "    :param text: Input text (string).\n",
    "    :return: Cleaned text (string).\n",
    "\n",
    "    Example:\n",
    "    >>> input_text = \"An example text with special characters: $100 and URLs like https://example.com.\"\n",
    "    >>> preprocess_text(input_text)\n",
    "    'example text special characters URLs like'\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    # Remove extra spaces and replace \"\\n\" with a space\n",
    "    text = re.sub(\"\\s\\s+\", \" \", text).replace(\"\\n\", \" \")\n",
    "    # Remove Non-English characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', \"\", text)\n",
    "    # Remove start and end white spaces\n",
    "    text = text.strip()\n",
    "    # Remove single characters\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", text)\n",
    "    # Remove punctuations\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]+\", \" \", text)\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Stopword Removal\n",
    "    text = ' '.join([word for word in text.split() if word not in nltk_stop])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a64d00",
   "metadata": {},
   "source": [
    "### Tokenisation and Lemmatisation\n",
    "\n",
    "This code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5276c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(documents):\n",
    "    \"\"\"\n",
    "    Tokenize a list of documents and perform the following:\n",
    "    1. Break text into individual words or subword tokens.\n",
    "    2. Reduce words to their base or root form using lemmatization.\n",
    "    3. Remove stop words and non-alphabetic characters.\n",
    "\n",
    "    Utilises spaCy's nlp.pipe for efficient batch processing.\n",
    "\n",
    "    :param documents: List of strings representing documents.\n",
    "    :return: List of lists of strings, where each list corresponds to the lemmatized tokens of a document.\n",
    "    \"\"\"\n",
    "    lemmatized_tokens_list = []\n",
    "    \n",
    "    # Process documents using spaCy's nlp.pipe with \"ner\" and \"parser\" components disabled\n",
    "    for doc in nlp.pipe(documents, disable=[\"ner\", \"parser\"], batch_size=5000):\n",
    "        # Generate lemmatised tokens, remove stop words, and non-alphabetic characters\n",
    "        lemmatized_tokens = [token.lemma_ for token in doc if token.is_alpha and token.lemma_ not in nlp.Defaults.stop_words]\n",
    "        lemmatized_tokens_list.append(lemmatized_tokens)\n",
    "\n",
    "    return lemmatized_tokens_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01717088",
   "metadata": {},
   "source": [
    "In many tokenization tasks, especially when you're primarily interested in lemmatization and removing stop words, you may not need the additional information provided by the \"ner\" and \"parser\" components.\n",
    "\n",
    "Disabling the \"ner\" and \"parser\" components during the processing of documents with nlp.pipe will reduce computational laod and can significantly improve efficiency and speed, especially when dealing with a large amount of text data.\n",
    "\n",
    "It's a trade-off between computational resources and the specific linguistic information your task requires. If named entities and syntactic parsing are not critical for your task, disabling these components is a pragmatic approach to enhance processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e1c7971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>congratulations well use tools well talk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry word nonsense offensive anyway intending...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation edits made username hardcore metal...      0   \n",
       "1  000103f0d9cfb60f  aww matches background colour seemingly stuck ...      0   \n",
       "2  000113f07ec002fd  hey man really trying edit war guy constantly ...      0   \n",
       "3  0001b41b1c6bb37e  make real suggestions improvement wondered sec...      0   \n",
       "4  0001d958c54c6e35                      sir hero chance remember page      0   \n",
       "5  00025465d4725e87           congratulations well use tools well talk      0   \n",
       "6  0002bcb3da6cb337                        cocksucker piss around work      1   \n",
       "7  00031b1e95af7921  vandalism matt shirvington article reverted pl...      0   \n",
       "8  00037261f536c51d  sorry word nonsense offensive anyway intending...      0   \n",
       "9  00040093b2687caa               alignment subject contrary dulithgow      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to train data\n",
    "df['comment_text'] = df['comment_text'].apply(preprocess_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2f74110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>thank understanding think highly would revert ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>dear god site horrible</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>somebody invariably try add religion really me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>says right type type institution needed case t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>adding new product list make sure relevant add...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>one 1897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>reason banning throwing article needs section ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>blocked editing wikipedia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>arabs committing genocide iraq protests europe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>please stop continue vandalize wikipedia homos...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0001ea8717f6de06  thank understanding think highly would revert ...      0   \n",
       "1  000247e83dcc1211                             dear god site horrible      0   \n",
       "2  0002f87b16116a7f  somebody invariably try add religion really me...      0   \n",
       "3  0003e1cccfd5a40a  says right type type institution needed case t...      0   \n",
       "4  00059ace3e3e9a53  adding new product list make sure relevant add...      0   \n",
       "5  000663aff0fffc80                                           one 1897      0   \n",
       "6  000689dd34e20979  reason banning throwing article needs section ...      0   \n",
       "7  000844b52dee5f3f                          blocked editing wikipedia      0   \n",
       "8  00091c35fa9d0465  arabs committing genocide iraq protests europe...      1   \n",
       "9  000968ce11f5ee34  please stop continue vandalize wikipedia homos...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             0        0       0       0              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to test data\n",
    "df_test['comment_text'] = df_test['comment_text'].apply(preprocess_text)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52566628",
   "metadata": {},
   "source": [
    "### 2.2 Requirements\n",
    "\n",
    "We're going to review the data and it's Perform detailed data analysis of the dataset provided by the competition, observing:\n",
    "\n",
    "Number of sentences and tokens per class (and check if the dataset is unbalanced or not).\n",
    "\n",
    "Analyse the most common words for each class and, therefore, understand the most used terms for each level of toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052425c",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "    \n",
    "### Create a TF-IDF \n",
    "vectoriser = TfTfidfVectorizer()\n",
    "transformed_output = v.fit_transform(\n",
    "print(v.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
